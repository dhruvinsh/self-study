#+TITLE: Big O
#+AUTHOR: Dhruvin Shah
#+EMAIL: dhruvin3@gmail.com
#+DESCRIPTION: This document provides summary of Big O notaion and basic rules
#+DATE: 2022-03-11
#+LANGUAGE:  en
#+STARTUP: showall
#+OPTIONS: \n:t

* BIG O
  What is O stands for? \\
  The letter O was chosen by Bachmann to stand for Ordnung, meaning the order of approximation
** Rules
Reference: [[https://www.youtube.com/watch?v=v4cd1O4zkGw][HackerRank - Big O Notation]]
-----
*** Different steps gets added
#+BEGIN_SRC python
def foo():  # Total runtime O(a+b)
    bar();  # O(a)
    baz();  # O(b)
#+END_SRC
*** Drop constants (we just need overview of runtime)
#+BEGIN_SRC python
def min_max(array):  # Total runtime O(2N) => drop constants hence O(N)
min = max = None
for i in array:  # runtime O(N)
    min = min([i, min])
for i in array:  # runtime O(N)
    max = max([i, max])
return min, max
#+END_SRC

#+BEGIN_SRC python
def min_max(array):  # Total runtime O(N)
min = max = None
for i in array:
    min = min([i, min])
    max = max([i, max])
return min, max
#+END_SRC
*** Different inputs --> different variables
#+BEGIN_SRC python
# here two nested loop, and we might think that
# runtime is O(N^2^) but what does N suggest here?
# here actual runtime is O(a * b)
def intersection_size(array_a, array_b):
c = 0
for a in array_a:
    for b in array_b:
    if a == b:
        c += 1
return c
#+END_SRC
*** *Drop non-dominante terms*
#+BEGIN_SRC python
# here total runtime we can calcuate as O(N+N^2^)
# Which is O(N^2^) <= O(N+N^2^) <= O(N^2^ + O^2^)
# based on above we can drop the non-dominat here
# so total runtime becomes O(N^2^)
def foo(array):
max = None
for i in array:  # runtime is O(N)
    max = max([i, max])
print(max)

for a in array: # runtime is O(N^2^) Hint: same array unlike above
    for b in array:
    print(a,b)
#+END_SRC


* LeetCode Explaination
** Describe
Less time and space that is better.

Time measurement: \\
    Start-stop for code execution not perfect, what if faster computer? \\
    Correct way is to count number of operation like assignment, arithmetic operatoin"

#+CAPTION: value of Big O for various name
| *Name*      | *Big O*    |
|-------------+------------|
| Constant    | O(c)       |
| Logarithmic | O(log(n))  |
| Linear      | O(n)       |
| Log Linear  | O(nlog(n)) |
| Quadratic   | O(n^2)     |
| Cubic       | O(n^3)     |
| Exponential | O(2^n)     |
-----
eg:
*** Good Example
#+BEGIN_SRC python
nums = [1, 2, 3, 4]
n = len(nums)
print("sum of array: ", n*(n+1)/2)
#+END_SRC

Here 1 assignment, 1 addition, 1 multiplication, 1 devision
Runtime (time) complexity is O(1)
See the example bleow:
#+CAPTION: Time Complexity O(1)
#+NAME: BigO Complexity O(1)
[[img:img/BigO-Describe-Example-1.jpg][Example-1]]

*** Bad Example
#+BEGIN_SRC python
nums = [1, 2, 3, 4]
n = len(nums)
sum = 0

for i in range(0, n):
sum+=nums[i]
print("Sum of array: ", sum)
#+END_SRC

Here n number of addition, n assignment \\
Time complexity is 5N + 3 \\
See the example below: \\
#+CAPTION: Time Complexity O(N)
#+NAME: BigO Complexity O(N)
[[img:img/BigO-Describe-Example-2.jpg][Example-2]]

** Simplify
- Just syats that ignore smaller terms: eg O(5N+3) is actually O(N)
- Arithmetic operations, assignments are constants
- Direct array element access (by index) is a constant

** Define time complexity and space complexity
Time complexity concern with number of operation whereas space complexity concern with memory usage

- Based on input variables how much runtime increase was all the talk about time complexity
- Memory consumption during algorithms execution comes under space complexity
  + Space only taken by algorithm, not by input

*** Space complexity of popular data structures
#+CAPTION: various data structures complexities
| *Name*            | *Big O* |
|-------------------+---------|
| Hash tables(dict) | O(N)    |
| Stacks            | O(N)    |
| Queues            | O(N)    |
| Strings           | O(N)    |
| Arrays            | O(N)    |
| 2d Arrays         | O(N*M)  |

** Find time/space complexity of algorithms
#+BEGIN_SRC python
def get_arr_upto(n):
    arr = []
    for i in range(n):
    arr.append(i)
    return arr
#+END_SRC

1. what is the space complexity? \\
   O(N) --> array increase by the append and limited to size of n
2. what is the time complexity? \\
   O(N) --> loop over the n data

** Describe logarithms
- what is log? \\
  log,2,(16) = 4            ==>     2^4^ = 16 \\
  log,2,(value) = exponent  ==>     2^exponent^ = value

  usually we ignore base of 2. so log = log,2,

- what do they represents? \\
  The number of times you can divide a number by the log's base, before you get a value that's less than or equal to 1.

- Example of algorithms with complexities that involv logs?
  +  Binary search ( log(N) ) (better then O(N) :D )
  +  Merge sort ( N*log(N) )

* Reference
- [[file:big-o-cheatsheet.pdf][Big O Cheatsheet.pdf]]
- [[img:img/big-o-cheatsheet.png][Big O Cheatsheet.png]]
